{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tELtL6R8y8AU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "fbf672b2-0add-4eb3-fba1-442418d952c9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2c1d61b27a20>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0muber_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"/content/uberdrive.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/uberdrive.csv'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "matplotlib.style.use('ggplot')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import datetime\n",
        "%matplotlib inline\n",
        "uber_df = pd.read_csv(r\"/content/uberdrive.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q1. Show the last 10 records of the dataset\n",
        "uber_df.tail(10)"
      ],
      "metadata": {
        "id": "KrTpBNQ70DV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q2. Show the first 10 records of the dataset.\n",
        "uber_df.head(10)"
      ],
      "metadata": {
        "id": "UsGuz_6e0V9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q3. Show the dimension of the dataset.\n",
        "uber_df.shape"
      ],
      "metadata": {
        "id": "5ZeyvGE20iN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q4. Show the size of the dataset.\n",
        "uber_df.size"
      ],
      "metadata": {
        "id": "_47ntxJW0v-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q5. Print the information about all the variables of the data set.\n",
        "uber_df.info()"
      ],
      "metadata": {
        "id": "lL8Ux2eW4L8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q Checking for duplicate data.\n",
        "# Check for duplicate values\n",
        "duplicates = uber_df.duplicated()\n",
        "# Count the number of duplicate values\n",
        "num_duplicates = uber_df.duplicated().sum()\n",
        "# Print the number of duplicate values\n",
        "print(\"Number of duplicate values:\", num_duplicates)\n",
        "# Print the duplicate rows\n",
        "print(uber_df[duplicates])"
      ],
      "metadata": {
        "id": "H0qd4h46ZE8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicate values and create a new dataset\n",
        "new_uber = uber_df.drop_duplicates()\n",
        "print(\"size after removing duplicate values\")\n",
        "new_uber.size\n",
        "new_uber.head(5)"
      ],
      "metadata": {
        "id": "0bit2vPTcsD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q7. How many missing values are present?\n",
        "new_uber.isnull().values.sum()"
      ],
      "metadata": {
        "id": "MOLPmExt4RDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out rows with \"Totals\" in 'START_DATE*' or 'END_DATE*' columns\n",
        "new_uber = new_uber[new_uber['START_DATE*'] != 'Totals']\n",
        "new_uber = new_uber[new_uber['END_DATE*'] != 'Totals']\n",
        "\n",
        "# Convert 'START_DATE*' and 'END_DATE*' columns to datetime objects\n",
        "new_uber['START_DATE*'] = pd.to_datetime(new_uber['START_DATE*'])\n",
        "new_uber['END_DATE*'] = pd.to_datetime(new_uber['END_DATE*'])\n",
        "\n",
        "# Calculate the time duration and create a new 'time_duration' column\n",
        "new_uber['time_duration'] = new_uber['END_DATE*'] - new_uber['START_DATE*']\n",
        "\n",
        "# Display the updated DataFrame\n",
        "new_uber.head(5)"
      ],
      "metadata": {
        "id": "1BJA0Q8EbIwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_uber.isnull().sum()"
      ],
      "metadata": {
        "id": "mkushHDB4bAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q8. Get the initial data (name it 'df') with dropping the NA values.\n",
        "df =new_uber.dropna()\n",
        "df.isnull().values.any()"
      ],
      "metadata": {
        "id": "V04rtcpK4epr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "euatrBTT4up0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q9. Get the summary of the original data (before dropping the 'null' values).\n",
        "uber_df.describe()"
      ],
      "metadata": {
        "id": "jO5FTU1v437t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q10. Check the information of the new dataframe.\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "g2fOZHMs6TC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uber_df.head(5)"
      ],
      "metadata": {
        "id": "QhKQGeel6Zwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q11. Get the unique start destinations.\n",
        "#Note: This question is based on the dataframe with 'na' values in the 'START' variable.\n",
        "len(uber_df[\"START*\"].unique())"
      ],
      "metadata": {
        "id": "4wcQuogU6gRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "un_start_destination = uber_df[\"START*\"].dropna()\n",
        "unique_start = set(un_start_destination)\n",
        "unique_start"
      ],
      "metadata": {
        "id": "dccVNlgA7QPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q12. What is the total number of unique start destinations?\n",
        "#Note: This question is based on the dataframe with no 'na' values in the 'START' variable.\n",
        "len(unique_start)"
      ],
      "metadata": {
        "id": "4gblH0zB8BjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q13. Print the total number of unique stop destinations.\n",
        "#Note: This question is based on the dataframe with no 'na' values in the 'STOP' variable.\n",
        "b = set(uber_df[\"STOP*\"])\n",
        "len(b)"
      ],
      "metadata": {
        "id": "v3GDtWkK8OPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_destination = uber_df[\"STOP*\"].dropna()\n",
        "unique_stop = set(stop_destination)\n",
        "len(unique_stop)\n"
      ],
      "metadata": {
        "id": "llBhePQv8aRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q14. [a] Print all the Uber trips that has the starting point of San Francisco.\n",
        "#Note: Use the original dataframe without dropping the 'na' values.\n",
        "uber_df[uber_df['START*']=='San Francisco']\n",
        "#OR\n",
        "#uber_df.loc[uber_df[\"START*\"] == \"San Francisco\"]"
      ],
      "metadata": {
        "id": "7mN9QxbD99t3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(uber_df[uber_df['START*']=='San Francisco'])\n"
      ],
      "metadata": {
        "id": "z8zA0CIX-UYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#[b] stop is either in katy or berkeley\n",
        "uber_df[uber_df['STOP*'].isin(['Katy','Berkeley'])]"
      ],
      "metadata": {
        "id": "PGmmfYue-XFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#[c] trip start in Central,Austin,San Francisco\n",
        "uber_df[uber_df['START*'].isin(['San Francisco','Central','Austin'])]"
      ],
      "metadata": {
        "id": "gMzIH2Gy-o_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#[d] trip either stop at katy or berkely or either start in san francisco , central or austin\n",
        "uber_df[uber_df['STOP*'].isin(['Katy','Berkeley']) | uber_df['START*'].isin(['San Francisco','Central','Austin'])]"
      ],
      "metadata": {
        "id": "-WwXsLJC-0K3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q15. What is the most popular starting point for the Uber drivers?\n",
        "#Note: This question is based on the dataframe with no 'na' values in the 'START' variable.\n",
        "starting_point = uber_df[\"START*\"].dropna()\n",
        "print(\"non null starting point\")\n",
        "starting_point"
      ],
      "metadata": {
        "id": "cqApXBQ5_UOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "starting_points = uber_df[\"START*\"].dropna()\n",
        "# Count the occurrences of each starting point\n",
        "starting_point_counts = starting_points.value_counts()\n",
        "# Get the most popular starting point\n",
        "most_popular_starting_point = starting_point_counts.idxmax()\n",
        "print(\"The most popular starting point for Uber drivers is:\", most_popular_starting_point)\n",
        "number_of_trips = starting_point_counts.max()\n",
        "print(\"Number of trips from this starting point:\", number_of_trips)\n"
      ],
      "metadata": {
        "id": "-2kKqA9eAyII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q16. What is the most popular dropping point for the Uber drivers?\n",
        "#Note: This question is based on the dataframe with no 'na' values in the 'STOP' variable.\n",
        "\n",
        "dropping_point_counts = uber_df['STOP*'].value_counts()\n",
        "# Get the most popular dropping point and its corresponding number of trips\n",
        "most_popular_dropping_point = dropping_point_counts.idxmax()\n",
        "number_of_trips = dropping_point_counts.max()\n",
        "\n",
        "# Print the result\n",
        "print(\"The most popular dropping point for Uber drivers is:\", most_popular_dropping_point)\n",
        "print(\"Number of trips to this dropping point:\", number_of_trips)\n"
      ],
      "metadata": {
        "id": "uHGCp7j_EEum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q17. List the most frequent route taken by Uber drivers.\n",
        "#Note: This question is based on the dataframe with no 'na' values.\n",
        "df = uber_df.dropna()\n",
        "df = pd.DataFrame(df.groupby(['START*', 'STOP*']).size())\n",
        "df = df.rename(columns = {0:'Count'})\n",
        "df = df.sort_values(['Count'], ascending = False)\n",
        "df.loc[df['Count'] == max(df['Count'])]"
      ],
      "metadata": {
        "id": "YlJktnvnElB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q18. Print all types of purposes for the trip in an array.\n",
        "#Note: This question is based on the dataframe with no 'na' values in the 'PURPOSE' variable.\n",
        "print(np.array(uber_df['PURPOSE*'].dropna().unique()))\n",
        "uber_df['MILES*'].groupby(uber_df['PURPOSE*']).sum()"
      ],
      "metadata": {
        "id": "hv-e598SE4pJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q19. Plot a bar graph of Purposes vs Distance.\n",
        "df1 = pd.DataFrame(uber_df['MILES*'].groupby(uber_df['PURPOSE*']).sum())\n",
        "df1.plot(kind = 'bar')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UHrU7UASFBQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q20. Print a dataframe of Purposes and the distance travelled for that particular Purpose.\n",
        "df1"
      ],
      "metadata": {
        "id": "-CKpXQKsFWKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q21. Plot number of trips vs Category of trips.\n",
        "uber_df.head()\n",
        "\n",
        "df2 = pd.DataFrame(uber_df['CATEGORY*'].value_counts())\n",
        "df2.reset_index()\n",
        "\n",
        "df2.plot(kind = 'bar')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9uim5yT8Fban"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q22. What is proportion of trips that is Business and what is the proportion of trips that is Personal?\n",
        "df3 = uber_df.groupby(['CATEGORY*']).sum()\n",
        "df3\n"
      ],
      "metadata": {
        "id": "D5YGsdGrFkXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = uber_df.groupby(['CATEGORY*']).sum()\n",
        "Business = df4.iloc[0,0]/(df.iloc[0,0] + df4.iloc[1,0])\n",
        "Personal = df4.iloc[1,0]/(df.iloc[0,0] + df4.iloc[1,0])\n",
        "print(\"Business:\", Business)\n",
        "print(\"Personal:\", Personal)"
      ],
      "metadata": {
        "id": "jQdcKSDiGdaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q24 plot number of trip at each category\n",
        "x = uber_df['CATEGORY*'].value_counts().plot(kind='bar')\n"
      ],
      "metadata": {
        "id": "JauYCpNRGgbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q25Number of trips per Month\n",
        "uber_df['START_DATE*'] = pd.to_datetime(uber_df['START_DATE*'], errors='coerce')\n",
        "uber_df['END_DATE*'] = pd.to_datetime(uber_df['END_DATE*'], errors='coerce')\n",
        "\n",
        "# Drop rows with missing datetime values\n",
        "uber_df = uber_df.dropna(subset=['START_DATE*', 'END_DATE*'])\n",
        "\n",
        "# Extract the month from the 'START_DATE*' column and create a new column 'Month'\n",
        "uber_df['Month'] = uber_df['START_DATE*'].dt.month\n",
        "\n",
        "# Group the data by month and count the number of trips\n",
        "trips_per_month = uber_df['Month'].value_counts().sort_index()\n",
        "\n",
        "# Create a bar graph\n",
        "plt.bar(trips_per_month.index, trips_per_month.values)\n",
        "\n",
        "# Set the labels and title\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Number of Trips')\n",
        "plt.title('Number of Trips per Month')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dLGo6NFcG5t-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q26 Number of trips per hour\n",
        "# Convert the 'START_DATE*' column to datetime format\n",
        "uber_df['START_DATE*'] = pd.to_datetime(uber_df['START_DATE*'])\n",
        "\n",
        "# Extract the hour from the 'START_DATE*' column and create a new column 'Hour'\n",
        "uber_df['Hour'] = uber_df['START_DATE*'].dt.hour\n",
        "\n",
        "# Group the data by hour and count the number of trips\n",
        "trips_per_hour = uber_df['Hour'].value_counts().sort_index()\n",
        "\n",
        "# Create a line graph\n",
        "plt.plot(trips_per_hour.index, trips_per_hour.values, marker='o')\n",
        "\n",
        "# Set the labels and title\n",
        "plt.xlabel('Hour')\n",
        "plt.ylabel('Number of Trips')\n",
        "plt.title('Number of Trips per Hour')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ddqCaZaAG56p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q27 see how many trips made by each purpose\n",
        "purpose_time = uber_df['PURPOSE*'].value_counts()\n",
        "purpose_time.plot(kind='bar',figsize=(10,5),color='green')"
      ],
      "metadata": {
        "id": "rVBTWylpLBLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q28 aveverage of each trip according to purpose\n",
        "purpose = uber_df.groupby('PURPOSE*').mean()\n",
        "purpose.plot(kind = 'bar',figsize=(15,5))"
      ],
      "metadata": {
        "id": "V-B4fWkHLFnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q29 calculate trip speed for each driver\n",
        "# Calculate the trip speed for each trip\n",
        "uber_df['TRIP_SPEED'] = uber_df['MILES*'] / (uber_df['END_DATE*'] - uber_df['START_DATE*']).dt.total_seconds() * 3600\n",
        "\n",
        "# Print the trip speed for each trip\n",
        "print(uber_df['TRIP_SPEED'])"
      ],
      "metadata": {
        "id": "AHYs8u3aLF4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#30 Average trip distance\n",
        "average_distance = uber_df['MILES*'].mean()\n",
        "print(\"Average trip distance:\", average_distance)"
      ],
      "metadata": {
        "id": "DkPBoH3uNlzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#31 busiest day of a week\n",
        "# Count the number of trips for each day of the week\n",
        "busiest_days = uber_df['START_DATE*'].dt.day_name().value_counts().sort_index()\n",
        "\n",
        "# Create a bar plot of the busiest days in ascending order\n",
        "plt.bar(busiest_days.index, busiest_days.values)\n",
        "plt.xlabel('Day of the Week')\n",
        "plt.ylabel('Number of Trips')\n",
        "plt.title('Busiest Day of the Week')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F81kOKFuO9W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#32  Peak hours for trips:\n",
        "# Extract the hour from the START_DATE* column\n",
        "uber_df['HOUR'] = uber_df['START_DATE*'].dt.hour\n",
        "\n",
        "# Count the number of trips for each hour\n",
        "peak_hours = uber_df['HOUR'].value_counts().sort_index()\n",
        "\n",
        "# Create a bar plot of the peak hours\n",
        "plt.bar(peak_hours.index, peak_hours.values)\n",
        "plt.xlabel('Hour')\n",
        "plt.ylabel('Number of Trips')\n",
        "plt.title('Peak Hours for Trips')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rGUEf1kLPFbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#33  Correlation between Trip Distance and Trip Duration:\n",
        "# Convert the start and stop time columns to datetime objects\n",
        "uber_df['START_DATE*'] = pd.to_datetime(uber_df['START_DATE*'])\n",
        "uber_df['END_DATE*'] = pd.to_datetime(uber_df['END_DATE*'])\n",
        "\n",
        "# Calculate the trip duration in minutes\n",
        "uber_df['TRIP_DURATION'] = (uber_df['END_DATE*'] - uber_df['START_DATE*']).dt.total_seconds() / 60\n",
        "\n",
        "# Select the columns for trip distance and trip duration\n",
        "trip_distance = uber_df['MILES*']\n",
        "trip_duration = uber_df['TRIP_DURATION']\n",
        "\n",
        "# Create a scatter plot of trip distance vs trip duration\n",
        "plt.scatter(trip_distance, trip_duration)\n",
        "plt.xlabel('Trip Distance')\n",
        "plt.ylabel('Trip Duration (minutes)')\n",
        "plt.title('Correlation between Trip Distance and Trip Duration')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DljJwPYHPgcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q34 Correlation between Trip Duration and Time of Day\n",
        "# Convert the start and stop time columns to datetime objects\n",
        "uber_df['START_DATE*'] = pd.to_datetime(uber_df['START_DATE*'])\n",
        "uber_df['END_DATE*'] = pd.to_datetime(uber_df['END_DATE*'])\n",
        "\n",
        "# Extract the time of day from the start and stop time\n",
        "uber_df['START_TIME'] = uber_df['START_DATE*'].dt.time\n",
        "uber_df['STOP_TIME'] = uber_df['END_DATE*'].dt.time\n",
        "\n",
        "# Calculate the trip duration in minutes\n",
        "uber_df['TRIP_DURATION'] = (uber_df['END_DATE*'] - uber_df['START_DATE*']).dt.total_seconds() / 60\n",
        "\n",
        "# Extract the hour from the start time\n",
        "uber_df['HOUR'] = uber_df['START_DATE*'].dt.hour\n",
        "\n",
        "# Select the columns for trip duration and hour of the day\n",
        "trip_duration = uber_df['TRIP_DURATION']\n",
        "hour_of_day = uber_df['HOUR']\n",
        "\n",
        "# Create a scatter plot of trip duration vs hour of the day\n",
        "plt.scatter(hour_of_day, trip_duration)\n",
        "plt.xlabel('Hour of the Day')\n",
        "plt.ylabel('Trip Duration (minutes)')\n",
        "plt.title('Correlation between Trip Duration and Time of Day')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rN-oUmVfVkp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q35 Average Trip Duration\n",
        "# Convert the start and stop time columns to datetime objects\n",
        "uber_df['START_DATE*'] = pd.to_datetime(uber_df['START_DATE*'])\n",
        "uber_df['END_DATE*'] = pd.to_datetime(uber_df['END_DATE*'])\n",
        "\n",
        "# Calculate the trip duration in minutes\n",
        "uber_df['TRIP_DURATION'] = (uber_df['END_DATE*'] - uber_df['START_DATE*']).dt.total_seconds() / 60\n",
        "\n",
        "# Extract the hour of the day from the start time\n",
        "uber_df['HOUR'] = uber_df['START_DATE*'].dt.hour\n",
        "\n",
        "# Group the data by the hour of the day and calculate the average trip duration\n",
        "grouped_data = uber_df.groupby('HOUR')['TRIP_DURATION'].mean()\n",
        "\n",
        "# Create a line plot of average trip duration\n",
        "plt.plot(grouped_data.index, grouped_data.values)\n",
        "plt.xlabel('Hour of the Day')\n",
        "plt.ylabel('Average Trip Duration (minutes)')\n",
        "plt.title('Average Trip Duration in a Day')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cA6wBZaqWGGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have features X and target variable y\n",
        "X = uber_df[['MILES*']]  # Replace with the features you want to use\n",
        "y = uber_df['TRIP_DURATION']  # Target variable\n",
        "\n",
        "# Split the data into a training set and a testing set (e.g., 80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Create a linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the mean squared error and R-squared (coefficient of determination)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print the model's performance metrics\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"R-squared:\", r2)\n"
      ],
      "metadata": {
        "id": "NB5TeL63Bc69"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}